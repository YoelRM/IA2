{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div><div style=\"float:left; clear:both;\"><img src=\"img/colab.png\" align=\"left\" width=\"200\" height=\"200\" /><br></div><div style=\"float:left; clear:both;\"><a href=\"https://colab.research.google.com/drive/1nVjFw-o83JHV9KYVQx5XXraa7awcLIHS\">Abre este Jupyter en Google Colab</a></div></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# División del conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook se muestran algunos de los mecanismos más utilizados para la división del conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descripción\n",
    "NSL-KDD is a data set suggested to solve some of the inherent problems of the KDD'99 data set which are mentioned in. Although, this new version of the KDD data set still suffers from some of the problems discussed by McHugh and may not be a perfect representative of existing real networks, because of the lack of public data sets for network-based IDSs, we believe it still can be applied as an effective benchmark data set to help researchers compare different intrusion detection methods. Furthermore, the number of records in the NSL-KDD train and test sets are reasonable. This advantage makes it affordable to run the experiments on the complete set without the need to randomly select a small portion. Consequently, evaluation results of different research work will be consistent and comparable.\n",
    "\n",
    "### Ficheros de datos\n",
    "* <span style=\"color:green\">**KDDTrain+.ARFF**: The full NSL-KDD train set with binary labels in ARFF format</span>\n",
    "* KDDTrain+.TXT: The full NSL-KDD train set including attack-type labels and difficulty level in CSV format\n",
    "* KDDTrain+_20Percent.ARFF:\tA 20% subset of the KDDTrain+.arff file\n",
    "* KDDTrain+_20Percent.TXT:\tA 20% subset of the KDDTrain+.txt file\n",
    "* KDDTest+.ARFF:\tThe full NSL-KDD test set with binary labels in ARFF format\n",
    "* KDDTest+.TXT:\tThe full NSL-KDD test set including attack-type labels and difficulty level in CSV format\n",
    "* KDDTest-21.ARFF:\tA subset of the KDDTest+.arff file which does not include records with difficulty level of 21 out of 21\n",
    "* KDDTest-21.TXT:\tA subset of the KDDTest+.txt file which does not include records with difficulty level of 21 out of 21\n",
    "\n",
    "### Descarga de los ficheros de datos\n",
    "https://iscxdownloads.cs.unb.ca/iscxdownloads/NSL-KDD/#NSL-KDD\n",
    "\n",
    "### Referencias adicionales sobre el conjunto de datos\n",
    "_M. Tavallaee, E. Bagheri, W. Lu, and A. Ghorbani, “A Detailed Analysis of the KDD CUP 99 Data Set,” Submitted to Second IEEE Symposium on Computational Intelligence for Security and Defense Applications (CISDA), 2009._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Lectura del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arff\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kdd_dataset(data_path):\n",
    "    \"\"\"Lectura del conjunto de datos NSL-KDD.\"\"\"\n",
    "    with open(data_path, 'r') as train_set:\n",
    "        dataset = arff.load(train_set)\n",
    "    attributes = [attr[0] for attr in dataset[\"attributes\"]]\n",
    "    return pd.DataFrame(dataset[\"data\"], columns=attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_kdd_dataset(\"datasets/NSL-KDD/KDDTrain+.arff\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125973 entries, 0 to 125972\n",
      "Data columns (total 42 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   duration                     125973 non-null  float64\n",
      " 1   protocol_type                125973 non-null  object \n",
      " 2   service                      125973 non-null  object \n",
      " 3   flag                         125973 non-null  object \n",
      " 4   src_bytes                    125973 non-null  float64\n",
      " 5   dst_bytes                    125973 non-null  float64\n",
      " 6   land                         125973 non-null  object \n",
      " 7   wrong_fragment               125973 non-null  float64\n",
      " 8   urgent                       125973 non-null  float64\n",
      " 9   hot                          125973 non-null  float64\n",
      " 10  num_failed_logins            125973 non-null  float64\n",
      " 11  logged_in                    125973 non-null  object \n",
      " 12  num_compromised              125973 non-null  float64\n",
      " 13  root_shell                   125973 non-null  float64\n",
      " 14  su_attempted                 125973 non-null  float64\n",
      " 15  num_root                     125973 non-null  float64\n",
      " 16  num_file_creations           125973 non-null  float64\n",
      " 17  num_shells                   125973 non-null  float64\n",
      " 18  num_access_files             125973 non-null  float64\n",
      " 19  num_outbound_cmds            125973 non-null  float64\n",
      " 20  is_host_login                125973 non-null  object \n",
      " 21  is_guest_login               125973 non-null  object \n",
      " 22  count                        125973 non-null  float64\n",
      " 23  srv_count                    125973 non-null  float64\n",
      " 24  serror_rate                  125973 non-null  float64\n",
      " 25  srv_serror_rate              125973 non-null  float64\n",
      " 26  rerror_rate                  125973 non-null  float64\n",
      " 27  srv_rerror_rate              125973 non-null  float64\n",
      " 28  same_srv_rate                125973 non-null  float64\n",
      " 29  diff_srv_rate                125973 non-null  float64\n",
      " 30  srv_diff_host_rate           125973 non-null  float64\n",
      " 31  dst_host_count               125973 non-null  float64\n",
      " 32  dst_host_srv_count           125973 non-null  float64\n",
      " 33  dst_host_same_srv_rate       125973 non-null  float64\n",
      " 34  dst_host_diff_srv_rate       125973 non-null  float64\n",
      " 35  dst_host_same_src_port_rate  125973 non-null  float64\n",
      " 36  dst_host_srv_diff_host_rate  125973 non-null  float64\n",
      " 37  dst_host_serror_rate         125973 non-null  float64\n",
      " 38  dst_host_srv_serror_rate     125973 non-null  float64\n",
      " 39  dst_host_rerror_rate         125973 non-null  float64\n",
      " 40  dst_host_srv_rerror_rate     125973 non-null  float64\n",
      " 41  class                        125973 non-null  object \n",
      "dtypes: float64(34), object(8)\n",
      "memory usage: 40.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. División del conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se debe separar el conjunto de datos en los diferentes subconjuntos necesarios para realizar los procesos de entrenamiento, validación y pruebas. Sklearn tiene implementada la función **split_train_test**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Particionado aleatorio y Stratified Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn tiene implementa la función **train_test_split**, sin embargo, esta función por defecto realiza un particionado del conjunto de datos aleatorio para cada vez que se ejecuta el script. Aún añadiendo una semilla fija para generación aleatoria, cada vez que carguemos de nuevo el conjunto de datos se generarán nuevos subconjuntos. Esto puede ocasionar que después de mucho intentos, el algoritmo \"vea\" todo el conjunto de datos.\n",
    "\n",
    "Para solucionar este problema, Sklearn ha introducido el parámetro **shuffle** en la función **train_test_split**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos métodos para dividir el conjunto de datos estan bien si tienes un conjunto de datos muy grande, pero si no lo tienes, corres el riesgo de introducir **sampling bias**.\n",
    "\n",
    "Para evitar esto, se utiliza un metodo de sampling que se llama **Stratified sampling**. La población es dividida en subconjuntos homogéneos llamados **strata**. El objetivo es que no quede ninguna característica del conjunto de datos sin representación en ninguno de los conjuntos de datos para una o más características en particular.\n",
    "\n",
    "Sklearn introduce el parámetro **stratify** en la función **train_test_split** para controlar este comportamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_This stratify parameter makes a split so that the proportion of values in the sample produced will be the same as the proportion of values provided to parameter stratify._\n",
    "\n",
    "_For example, if variable y is a binary categorical variable with values 0 and 1 and there are 25% of zeros and 75% of ones, stratify=y will make sure that your random split has 25% of 0's and 75% of 1's._\n",
    "\n",
    "_https://stackoverflow.com/a/38889389_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generación de una función de particionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda-Test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
